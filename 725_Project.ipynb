{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "725_Project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6vW9tVvTk-D"
      },
      "source": [
        "## **725 Project Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9B1wxfGUI-o"
      },
      "source": [
        "## Load raw data\n",
        "\n",
        "It is publicly available in the UCI Machine learning Repository, which can be retrieved from\n",
        "\n",
        " http://archive.ics.uci.edu/ml/datasets/Bank+Marketing#\n",
        "\n",
        "There are a total of more than 40,000 observation each having 16 fields and the final answer is a binary variable of \"yes\" or \"no\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeG7vDXXB3Ov"
      },
      "source": [
        "##Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfWxuJk9UUKA"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pandas import read_csv\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import os\n",
        "from scipy.stats import zscore\n",
        "\n",
        "def cleandata(db):\n",
        "    dataset=db.copy()\n",
        "    dataset[['balance']].mean()\n",
        "    dataset['outliers'] = dataset['balance']\n",
        "    dataset['outliers']= zscore(dataset['outliers'])\n",
        "    condition = (dataset['outliers']>2.5) | (dataset['outliers']<-2.5 )\n",
        "    dataset = dataset.drop(dataset[condition].index, axis = 0, inplace = False)\n",
        "    dataset = dataset.drop('outliers', axis=1)\n",
        "\n",
        "    dataset.drop('contact', inplace=True, axis=1)\n",
        "\n",
        "    dataset['duration'] = dataset['duration'].div(60).round(2)\n",
        "\n",
        "    lst = [dataset]\n",
        "    for column in lst:\n",
        "        column.loc[column[\"month\"] == \"jan\", \"month_int\"] = 1\n",
        "        column.loc[column[\"month\"] == \"feb\", \"month_int\"] = 2\n",
        "        column.loc[column[\"month\"] == \"mar\", \"month_int\"] = 3\n",
        "        column.loc[column[\"month\"] == \"apr\", \"month_int\"] = 4\n",
        "        column.loc[column[\"month\"] == \"may\", \"month_int\"] = 5\n",
        "        column.loc[column[\"month\"] == \"jun\", \"month_int\"] = 6\n",
        "        column.loc[column[\"month\"] == \"jul\", \"month_int\"] = 7\n",
        "        column.loc[column[\"month\"] == \"aug\", \"month_int\"] = 8\n",
        "        column.loc[column[\"month\"] == \"sep\", \"month_int\"] = 9\n",
        "        column.loc[column[\"month\"] == \"oct\", \"month_int\"] = 10\n",
        "        column.loc[column[\"month\"] == \"nov\", \"month_int\"] = 11\n",
        "        column.loc[column[\"month\"] == \"dec\", \"month_int\"] = 12\n",
        "\n",
        "    condition = (dataset['duration']<10/60) | (dataset['education'] == 'unknown') | (dataset['job'] == 'unknown') | (dataset['poutcome'] == 'other') | (dataset['age'] >= 65)\n",
        "    dataset = dataset.drop(dataset[condition].index, axis = 0, inplace = False)\n",
        "    return dataset\n",
        "\n",
        "Path = r\"bank-full.csv\"\n",
        "dset = pd.read_csv(Path, sep = ';')\n",
        "data = cleandata(dset)\n",
        "data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPdEepc0dCVF"
      },
      "source": [
        "import seaborn as sns\n",
        "graph1 = sns.lmplot(x='duration', y='campaign',data = data,hue = 'y',fit_reg = False,)\n",
        "plt.axis([0,60,0,60])\n",
        "plt.ylabel('Frequency of Call')\n",
        "plt.xlabel('Call lenght')\n",
        "plt.axhline(y=5, linewidth=2, color=\"k\", linestyle='--')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHR9H-CIhNv6"
      },
      "source": [
        "sns.countplot(x='y', data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZQNqLlbhgmY"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20, 8)\n",
        "sns.boxplot(x='balance', data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmjjkS7vhqos"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(20, 8)\n",
        "sns.countplot(x='age', data=data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IxqbLW3dS97Q"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "df = data\n",
        "\n",
        "encoder = LabelEncoder()\n",
        "df['job'] = encoder.fit_transform(df['job'])\n",
        "df['marital'] = encoder.fit_transform(df['marital'])\n",
        "df['education'] = encoder.fit_transform(df['education'])\n",
        "df['default'] = encoder.fit_transform(df['default'])\n",
        "df['housing'] = encoder.fit_transform(df['housing'])\n",
        "df['loan'] = encoder.fit_transform(df['loan'])\n",
        "df['month'] = encoder.fit_transform(df['month'])\n",
        "df['poutcome'] = encoder.fit_transform(df['poutcome'])\n",
        "df['y'] = encoder.fit_transform(df['y'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c44-BnyEGyTB"
      },
      "source": [
        "fig, ax = plt.subplots()\n",
        "fig.set_size_inches(15,15)\n",
        "correlation = df.corr()\n",
        "correlation_plot = sns.heatmap(correlation, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bH1WIkQeIOCM"
      },
      "source": [
        "# X = df.drop(['y'], axis=1)[['duration','previous']]\n",
        "X = df.drop(['y'], axis=1)\n",
        "y = df['y']\n",
        "print(X.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGDY6iB2IOSb"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JS4btjE_B6lB"
      },
      "source": [
        "##Balancing Techniques"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKcmuYg9qANt"
      },
      "source": [
        "def oversampling_minority(X, y):\n",
        "  from sklearn.utils import resample\n",
        "  data = pd.concat([X, y], axis = 1)\n",
        "  positive = data[data.y==1]\n",
        "  negative = data[data.y==0]\n",
        "  positive_upsampled = resample(positive, replace=True, n_samples=len(negative), random_state=27)\n",
        "\n",
        "  upsampled_df = pd.concat([negative,positive_upsampled])\n",
        "\n",
        "  X = upsampled_df.drop('y', axis=1)\n",
        "  y = upsampled_df['y']\n",
        "  return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yl4ToLxxqAHJ"
      },
      "source": [
        "def undersampling_majority(X, y):\n",
        "  from sklearn.utils import resample\n",
        "  data = pd.concat([X, y], axis = 1)\n",
        "  positive = data[data.y==1]\n",
        "  negative = data[data.y==0]\n",
        "  negative_downsampled = resample(negative, replace=True, n_samples=len(positive), random_state=27)\n",
        "\n",
        "  downsampled_df = pd.concat([positive,negative_downsampled])\n",
        "\n",
        "  X = downsampled_df.drop('y', axis=1)\n",
        "  y = downsampled_df['y']\n",
        "  return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLJLydpdp__o"
      },
      "source": [
        "def applying_SMOTE(X, y):\n",
        "  from imblearn.over_sampling import SMOTE\n",
        "\n",
        "  sm = SMOTE(random_state=27, sampling_strategy=1.0)\n",
        "\n",
        "  X, y = sm.fit_resample(X, y)\n",
        "  \n",
        "  return X,y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnIWIGYXwHMg"
      },
      "source": [
        "#Apply Over/under sampling Here or SMOTE\n",
        "#X_train, y_train = oversampling_minority(X_train, y_train)\n",
        "#X_train, y_train = undersampling_majority(X_train, y_train)\n",
        "# X_train, y_train = applying_SMOTE(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz6WSdSLB-dQ"
      },
      "source": [
        "##Scaling the Feature Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yRZ404QIOVc"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEU-W1qFIYvk"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77a8RNqACF_T"
      },
      "source": [
        "##Support Vector Machines"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1eOELMvnIY0N"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# no effect of regularization C\n",
        "#svm = SVC(kernel = 'rbf',class_weight='balanced', probability=True)\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "m55zoadLIY3Y"
      },
      "source": [
        "def score(test, pred):\n",
        "  print(\"Confusion matrix\")\n",
        "  cf = confusion_matrix(test, pred)\n",
        "  print(cf)\n",
        "\n",
        "  print(\"Accuracy\")\n",
        "  print(round(accuracy_score(test, pred),2)*100)\n",
        "\n",
        "  print(\"Classification Report\")\n",
        "  print(metrics.classification_report(test, pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vfnBWkAqJN1m",
        "outputId": "b2dd5a66-6365-4356-d840-d200c51e491b"
      },
      "source": [
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "\n",
        "score(y_test, svmpred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[6899  142]\n",
            " [ 624  251]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7041\n",
            "           1       0.64      0.29      0.40       875\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.78      0.63      0.67      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IXGqLOIpKS8W"
      },
      "source": [
        "# Code snippet taken from Kaggle Notebook. https://www.kaggle.com/henriqueyamahata/bank-marketing-classification-roc-f1-recall\n",
        "\n",
        "def plot_ROC(probs):\n",
        "  fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, probs)\n",
        "  roc_aucgbk = metrics.auc(fprgbk, tprgbk)\n",
        "\n",
        "  plt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\n",
        "  plt.plot([0, 1], [0, 1],'r--')\n",
        "  plt.title('Receiver Operating Characteristic',fontsize=10)\n",
        "  plt.ylabel('True Positive Rate',fontsize=20)\n",
        "  plt.xlabel('False Positive Rate',fontsize=15)\n",
        "  plt.legend(loc = 'lower right', prop={'size': 16})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IyL1cTwxvZM8",
        "outputId": "e10fb28d-cc6d-4f78-b0dc-5c13e7a2bffe"
      },
      "source": [
        "plot_ROC(preds)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hyGLkCuq2On7"
      },
      "source": [
        "## Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "lRI05pv6OAVA",
        "outputId": "9a9faae5-48f2-4c5b-eda4-48ad58e6b726"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(16,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2416 - accuracy: 0.9016\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2186 - accuracy: 0.9077\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2115 - accuracy: 0.9110\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2064 - accuracy: 0.9125\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1998 - accuracy: 0.9141\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1955 - accuracy: 0.9162\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1911 - accuracy: 0.9171\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1888 - accuracy: 0.9188\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1851 - accuracy: 0.9205\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1826 - accuracy: 0.9209\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1798 - accuracy: 0.9221\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1772 - accuracy: 0.9238\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1748 - accuracy: 0.9239\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1715 - accuracy: 0.9256\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1685 - accuracy: 0.9271\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1667 - accuracy: 0.9268\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1639 - accuracy: 0.9282\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1611 - accuracy: 0.9307\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1595 - accuracy: 0.9319\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1566 - accuracy: 0.9340\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1534 - accuracy: 0.9344\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1507 - accuracy: 0.9346\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1481 - accuracy: 0.9384\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1463 - accuracy: 0.9384\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1425 - accuracy: 0.9405\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1397 - accuracy: 0.9411\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1379 - accuracy: 0.9419\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1340 - accuracy: 0.9439\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1323 - accuracy: 0.9450\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1289 - accuracy: 0.9454\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1268 - accuracy: 0.9466\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1235 - accuracy: 0.9485\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1216 - accuracy: 0.9490\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1181 - accuracy: 0.9496\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1161 - accuracy: 0.9512\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1112 - accuracy: 0.9540\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1106 - accuracy: 0.9537\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1069 - accuracy: 0.9548\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1042 - accuracy: 0.9572\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1027 - accuracy: 0.9580\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0998 - accuracy: 0.9585\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0962 - accuracy: 0.9603\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0958 - accuracy: 0.9606\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0924 - accuracy: 0.9633\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0889 - accuracy: 0.9639\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.9644\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0841 - accuracy: 0.9665\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0833 - accuracy: 0.9665\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0831 - accuracy: 0.9656\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0797 - accuracy: 0.9681\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7b7938f650>"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZTKIcPhx2ezs",
        "outputId": "06e54dfa-da15-484c-b347-1bff6fdb4bf5"
      },
      "source": [
        "model.evaluate(X_test, y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "248/248 [==============================] - 0s 1ms/step - loss: 0.3780 - accuracy: 0.8981\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.3779907524585724, 0.8980545997619629]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ONEpGxu6z_Ef",
        "outputId": "16ab2bd1-eae9-4de1-987d-7606418f7c4c"
      },
      "source": [
        "nn_pred = model.predict(X_test)\n",
        "#score(y_test, nn_pred)\n",
        "plot_ROC(nn_pred)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "\n",
        "score(y_test,nn_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[6690  351]\n",
            " [ 456  419]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.95      0.94      7041\n",
            "           1       0.54      0.48      0.51       875\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.74      0.71      0.73      7916\n",
            "weighted avg       0.89      0.90      0.90      7916\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Z7BuZyq63-Xg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MGcoS5zSI-gJ"
      },
      "source": [
        "##Decision tree Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "6QdGVISOJDR6",
        "outputId": "d66ec2aa-7d6d-41ae-b878-98179bc00a08"
      },
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=7)\n",
        "    # oversampling_minority  undersampling_majority \n",
        "    # newXtrain , newYtrain = applying_SMOTE(X_train,y_train)\n",
        "    \n",
        "    # X_train = newXtrain\n",
        "    # y_train = newYtrain\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    # print(confusion_matrix(Y_testingdata, predictions))\n",
        "    # print(round(accuracy_score(Y_testingdata, predictions),2)*100)\n",
        "    score(y_test,predictions)\n",
        "    \n",
        "    probs = model.predict_proba(X_test)[:,1]\n",
        "    plot_ROC(probs)\n",
        "    # plot_confusion_matrix(confusion_matrix(y_test, predictions), X_test, y_test)  \n",
        "   \n",
        "    #fprgbk, tprgbk, thresholdgbk = metrics.roc_curve(y_test, probs)\n",
        "    #roc_aucgbk = metrics.auc(fprgbk, tprgbk)\n",
        "\n",
        "    #plt.plot(fprgbk, tprgbk, 'b', label = 'AUC = %0.2f' % roc_aucgbk)\n",
        "    #plt.plot([0, 1], [0, 1],'r--')\n",
        "    #plt.title('Receiver Operating Characteristic Deci ',fontsize=10)\n",
        "    #plt.ylabel('True Positive Rate',fontsize=20)\n",
        "    #plt.xlabel('False Positive Rate',fontsize=15)\n",
        "    #plt.legend(loc = 'lower right', prop={'size': 16})\n",
        "\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[6817  224]\n",
            " [ 521  354]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      7041\n",
            "           1       0.61      0.40      0.49       875\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.77      0.69      0.72      7916\n",
            "weighted avg       0.89      0.91      0.90      7916\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7WYqf5syc9B"
      },
      "source": [
        "##Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "f3XM1s5yLILs",
        "outputId": "687e2d68-e114-419f-e150-fa46cc510089"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "probs = logreg.predict_proba(X_test)[:,1]\n",
        "plot_ROC(probs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "[[6910  131]\n",
            " [ 694  181]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      7041\n",
            "           1       0.58      0.21      0.30       875\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.74      0.59      0.62      7916\n",
            "weighted avg       0.87      0.90      0.87      7916\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "KTulPXwYKuLb"
      },
      "source": [
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "671zfhUtsxvD"
      },
      "source": [
        "##Ablation Study\n",
        "We divided the set of 16 features into 4 groups:\n",
        "\n",
        "Group 1: Client Information related features---age, job, marital, education, default\n",
        "\n",
        "Group 2: Banking related attributes---housing, loan, balance, month_int\n",
        "\n",
        "Group 3: Related to the last contact made---day, month, duration, campaign, pdays, previous, poutcome\n",
        "\n",
        "Group 4: Most important 5 features as can be seen from the Feature Importance---duration, balance, day, age"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HRRHmu3CQdLN",
        "outputId": "b3f6ec8a-a712-403d-b207-d143e95e5c1f"
      },
      "source": [
        "#Ablation Study\n",
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "      <th>month_int</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2143</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>4.35</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>2.52</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>1.27</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>35</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>231</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>2.32</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>28</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>447</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>3.62</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45202</th>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>557</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>3.73</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45203</th>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>113</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>4.43</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45205</th>\n",
              "      <td>25</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>505</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>6.43</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45206</th>\n",
              "      <td>51</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>825</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>16.28</td>\n",
              "      <td>3</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45209</th>\n",
              "      <td>57</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>668</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>17</td>\n",
              "      <td>9</td>\n",
              "      <td>8.47</td>\n",
              "      <td>4</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>11.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>39579 rows  17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       age  job  marital  education  ...  previous  poutcome  y  month_int\n",
              "0       58    4        1          2  ...         0         2  0        5.0\n",
              "1       44    9        2          1  ...         0         2  0        5.0\n",
              "2       33    2        1          1  ...         0         2  0        5.0\n",
              "5       35    4        1          2  ...         0         2  0        5.0\n",
              "6       28    4        2          2  ...         0         2  0        5.0\n",
              "...    ...  ...      ...        ...  ...       ...       ... ..        ...\n",
              "45202   34    0        2          1  ...         0         2  1       11.0\n",
              "45203   23    8        2          2  ...         0         2  1       11.0\n",
              "45205   25    9        2          1  ...         0         2  1       11.0\n",
              "45206   51    9        1          2  ...         0         2  1       11.0\n",
              "45209   57    1        1          1  ...         0         2  0       11.0\n",
              "\n",
              "[39579 rows x 17 columns]"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BMTJEmVyvkbP"
      },
      "source": [
        "##Group 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VdsN5igCutEf",
        "outputId": "4883347a-9cab-4bfd-bc56-d735d2a86a30"
      },
      "source": [
        "gr1data = data.drop(columns=['balance','housing','loan','day','month','duration','campaign','pdays','previous','poutcome','month_int'])\n",
        "X = gr1data.drop(['y'], axis=1)\n",
        "y = gr1data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP1 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(5,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP1 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP1 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP1 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 5) (39579,)\n",
            "----------GROUP1 Using SVM------------\n",
            "Confusion matrix\n",
            "[[7036    0]\n",
            " [ 880    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7036\n",
            "           1       0.00      0.00      0.00       880\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.44      0.50      0.47      7916\n",
            "weighted avg       0.79      0.89      0.84      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.3466 - accuracy: 0.8917\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3367 - accuracy: 0.8917\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3354 - accuracy: 0.8917\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3345 - accuracy: 0.8917\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.8917\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3337 - accuracy: 0.8917\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3335 - accuracy: 0.8917\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3327 - accuracy: 0.8917\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3324 - accuracy: 0.8917\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3323 - accuracy: 0.8917\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3320 - accuracy: 0.8918\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3318 - accuracy: 0.8918\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3316 - accuracy: 0.8919\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3316 - accuracy: 0.8918\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3314 - accuracy: 0.8916\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3313 - accuracy: 0.8916\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3309 - accuracy: 0.8917\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3309 - accuracy: 0.8917\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3305 - accuracy: 0.8916\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3306 - accuracy: 0.8919\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3307 - accuracy: 0.8918\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3302 - accuracy: 0.8920\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3304 - accuracy: 0.8918\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3303 - accuracy: 0.8917\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3301 - accuracy: 0.8915\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3300 - accuracy: 0.8917\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3302 - accuracy: 0.8914\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8918\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3303 - accuracy: 0.8919\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3297 - accuracy: 0.8916\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8917\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3298 - accuracy: 0.8915\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3293 - accuracy: 0.8916\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3295 - accuracy: 0.8916\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3294 - accuracy: 0.8916\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3293 - accuracy: 0.8919\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8918\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3292 - accuracy: 0.8917\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3291 - accuracy: 0.8919\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3291 - accuracy: 0.8916\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8918\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8918\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8915\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8917\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3289 - accuracy: 0.8915\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3285 - accuracy: 0.8920\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3288 - accuracy: 0.8917\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3287 - accuracy: 0.8916\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3284 - accuracy: 0.8919\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3285 - accuracy: 0.8918\n",
            "-----------GROUP1 Using NN------------\n",
            "Confusion matrix\n",
            "[[7030    6]\n",
            " [ 872    8]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7036\n",
            "           1       0.57      0.01      0.02       880\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.73      0.50      0.48      7916\n",
            "weighted avg       0.85      0.89      0.84      7916\n",
            "\n",
            "-----------GROUP1 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[7036    0]\n",
            " [ 880    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7036\n",
            "           1       0.00      0.00      0.00       880\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.44      0.50      0.47      7916\n",
            "weighted avg       0.79      0.89      0.84      7916\n",
            "\n",
            "-----------GROUP1 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[7036    0]\n",
            " [ 880    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7036\n",
            "           1       0.00      0.00      0.00       880\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.44      0.50      0.47      7916\n",
            "weighted avg       0.79      0.89      0.84      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaAO0p_fzVIB"
      },
      "source": [
        "##Group2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Pxg107uwwrur",
        "outputId": "f490d6e9-7edf-45ec-dc11-66f8e90ee107"
      },
      "source": [
        "gr2data = data.drop(columns=['day','month','duration','campaign','pdays','previous','poutcome','age','marital','education','job','default'])\n",
        "X = gr2data.drop(['y'], axis=1)\n",
        "y = gr2data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP2 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(4,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP2 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP2 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP2 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 4) (39579,)\n",
            "----------GROUP2 Using SVM------------\n",
            "Confusion matrix\n",
            "[[7064    0]\n",
            " [ 852    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7064\n",
            "           1       0.00      0.00      0.00       852\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.45      0.50      0.47      7916\n",
            "weighted avg       0.80      0.89      0.84      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.3337 - accuracy: 0.8908\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3259 - accuracy: 0.8908\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3233 - accuracy: 0.8909\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3232 - accuracy: 0.8908\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3220 - accuracy: 0.8908\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3209 - accuracy: 0.8909\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3201 - accuracy: 0.8909\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3198 - accuracy: 0.8910\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3191 - accuracy: 0.8905\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3183 - accuracy: 0.8915\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3184 - accuracy: 0.8910\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3178 - accuracy: 0.8914\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3174 - accuracy: 0.8909\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3172 - accuracy: 0.8909\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3165 - accuracy: 0.8913\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3166 - accuracy: 0.8921\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3165 - accuracy: 0.8913\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3163 - accuracy: 0.8919\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3158 - accuracy: 0.8915\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3159 - accuracy: 0.8921\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3153 - accuracy: 0.8914\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3155 - accuracy: 0.8918\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3152 - accuracy: 0.8917\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3146 - accuracy: 0.8916\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3147 - accuracy: 0.8916\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3144 - accuracy: 0.8912\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3141 - accuracy: 0.8913\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3139 - accuracy: 0.8919\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3133 - accuracy: 0.8922\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3132 - accuracy: 0.8915\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3135 - accuracy: 0.8923\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3131 - accuracy: 0.8918\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.8913\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.8924\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3132 - accuracy: 0.8915\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3130 - accuracy: 0.8930\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3127 - accuracy: 0.8920\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3125 - accuracy: 0.8924\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3126 - accuracy: 0.8914\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3124 - accuracy: 0.8922\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3125 - accuracy: 0.8923\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3122 - accuracy: 0.8912\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8919\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3121 - accuracy: 0.8923\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3125 - accuracy: 0.8916\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3123 - accuracy: 0.8921\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3119 - accuracy: 0.8923\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3117 - accuracy: 0.8918\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3121 - accuracy: 0.8915\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3122 - accuracy: 0.8923\n",
            "-----------GROUP2 Using NN------------\n",
            "Confusion matrix\n",
            "[[7010   54]\n",
            " [ 785   67]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94      7064\n",
            "           1       0.55      0.08      0.14       852\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.73      0.54      0.54      7916\n",
            "weighted avg       0.86      0.89      0.86      7916\n",
            "\n",
            "-----------GROUP2 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[7064    0]\n",
            " [ 852    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7064\n",
            "           1       0.00      0.00      0.00       852\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.45      0.50      0.47      7916\n",
            "weighted avg       0.80      0.89      0.84      7916\n",
            "\n",
            "-----------GROUP2 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[7064    0]\n",
            " [ 852    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7064\n",
            "           1       0.00      0.00      0.00       852\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.45      0.50      0.47      7916\n",
            "weighted avg       0.80      0.89      0.84      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huwRoEZ_zoZ7"
      },
      "source": [
        "##Group 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wzB1YoNgzp5Y",
        "outputId": "e86e48f9-11ff-417f-fb83-fc70a9ae1797"
      },
      "source": [
        "gr3data = data.drop(columns=['balance','housing','loan','month_int','age','marital','education','job','default'])\n",
        "X = gr3data.drop(['y'], axis=1)\n",
        "y = gr3data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP3 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(7,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP3 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP3 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP3 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 7) (39579,)\n",
            "----------GROUP3 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6931  145]\n",
            " [ 575  265]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7076\n",
            "           1       0.65      0.32      0.42       840\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.78      0.65      0.69      7916\n",
            "weighted avg       0.89      0.91      0.89      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2544 - accuracy: 0.9001\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2370 - accuracy: 0.9060\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2323 - accuracy: 0.9072\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2283 - accuracy: 0.9083\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2260 - accuracy: 0.9090\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2232 - accuracy: 0.9101\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2210 - accuracy: 0.9104\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2183 - accuracy: 0.9112\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2154 - accuracy: 0.9125\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2132 - accuracy: 0.9131\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2107 - accuracy: 0.9130\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2087 - accuracy: 0.9147\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2068 - accuracy: 0.9148\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2048 - accuracy: 0.9148\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2025 - accuracy: 0.9149\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2013 - accuracy: 0.9161\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2003 - accuracy: 0.9166\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1987 - accuracy: 0.9182\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1977 - accuracy: 0.9183\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1971 - accuracy: 0.9184\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1955 - accuracy: 0.9190\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1951 - accuracy: 0.9183\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1944 - accuracy: 0.9196\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1926 - accuracy: 0.9209\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1919 - accuracy: 0.9191\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1908 - accuracy: 0.9207\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1904 - accuracy: 0.9204\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1900 - accuracy: 0.9211\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1898 - accuracy: 0.9205\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1888 - accuracy: 0.9220\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1874 - accuracy: 0.9210\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1872 - accuracy: 0.9221\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1859 - accuracy: 0.9228\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1853 - accuracy: 0.9234\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1854 - accuracy: 0.9230\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1843 - accuracy: 0.9232\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1834 - accuracy: 0.9232\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1826 - accuracy: 0.9226\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1828 - accuracy: 0.9238\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1810 - accuracy: 0.9248\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1813 - accuracy: 0.9241\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1811 - accuracy: 0.9237\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1798 - accuracy: 0.9259\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1795 - accuracy: 0.9248\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1790 - accuracy: 0.9260\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1777 - accuracy: 0.9253\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1773 - accuracy: 0.9268\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1771 - accuracy: 0.9257\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1761 - accuracy: 0.9270\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1757 - accuracy: 0.9275\n",
            "-----------GROUP3 Using NN------------\n",
            "Confusion matrix\n",
            "[[6837  239]\n",
            " [ 460  380]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      7076\n",
            "           1       0.61      0.45      0.52       840\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.78      0.71      0.74      7916\n",
            "weighted avg       0.90      0.91      0.91      7916\n",
            "\n",
            "-----------GROUP3 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6967  109]\n",
            " [ 689  151]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.95      7076\n",
            "           1       0.58      0.18      0.27       840\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.75      0.58      0.61      7916\n",
            "weighted avg       0.88      0.90      0.87      7916\n",
            "\n",
            "-----------GROUP3 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6863  213]\n",
            " [ 539  301]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      7076\n",
            "           1       0.59      0.36      0.44       840\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.76      0.66      0.70      7916\n",
            "weighted avg       0.89      0.91      0.89      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uh5rP2Glz7P8"
      },
      "source": [
        "##Group 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kr63kLbVz8GA",
        "outputId": "d5cb4a6e-5e04-463a-d052-fa25671a9159"
      },
      "source": [
        "gr4data = data.drop(columns=['housing','loan','month_int','marital','education','job','default','month','campaign','pdays','previous','poutcome'])\n",
        "X = gr4data.drop(['y'], axis=1)\n",
        "y = gr4data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(4,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 4) (39579,)\n",
            "----------GROUP4 Using SVM------------\n",
            "Confusion matrix\n",
            "[[7011   83]\n",
            " [ 680  142]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95      7094\n",
            "           1       0.63      0.17      0.27       822\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.77      0.58      0.61      7916\n",
            "weighted avg       0.88      0.90      0.88      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2817 - accuracy: 0.8953\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2690 - accuracy: 0.8958\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2674 - accuracy: 0.8965\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2667 - accuracy: 0.8960\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2656 - accuracy: 0.8965\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2650 - accuracy: 0.8966\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2639 - accuracy: 0.8965\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2634 - accuracy: 0.8971\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2628 - accuracy: 0.8970\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2623 - accuracy: 0.8974\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2611 - accuracy: 0.8980\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2614 - accuracy: 0.8975\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2608 - accuracy: 0.8983\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2606 - accuracy: 0.8978\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2598 - accuracy: 0.8979\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2595 - accuracy: 0.8984\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2590 - accuracy: 0.8984\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2589 - accuracy: 0.8981\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2582 - accuracy: 0.8979\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2579 - accuracy: 0.8983\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2574 - accuracy: 0.8981\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2574 - accuracy: 0.8986\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2570 - accuracy: 0.8982\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2563 - accuracy: 0.8981\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2563 - accuracy: 0.8976\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2561 - accuracy: 0.8984\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2556 - accuracy: 0.8982\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2554 - accuracy: 0.8986\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2547 - accuracy: 0.8982\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.8988\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2543 - accuracy: 0.8997\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2539 - accuracy: 0.8984\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2538 - accuracy: 0.8981\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2533 - accuracy: 0.8991\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2526 - accuracy: 0.8996\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2531 - accuracy: 0.8996\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2529 - accuracy: 0.8990\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2524 - accuracy: 0.8990\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2518 - accuracy: 0.8995\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2514 - accuracy: 0.8994\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2515 - accuracy: 0.8999\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2510 - accuracy: 0.8995\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2507 - accuracy: 0.9001\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2507 - accuracy: 0.8991\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2502 - accuracy: 0.8996\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2495 - accuracy: 0.9001\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2494 - accuracy: 0.8998\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2494 - accuracy: 0.8999\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2484 - accuracy: 0.9004\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2482 - accuracy: 0.9001\n",
            "-----------GROUP4 Using NN------------\n",
            "Confusion matrix\n",
            "[[6934  160]\n",
            " [ 628  194]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7094\n",
            "           1       0.55      0.24      0.33       822\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.73      0.61      0.64      7916\n",
            "weighted avg       0.88      0.90      0.88      7916\n",
            "\n",
            "-----------GROUP4 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[7004   90]\n",
            " [ 684  138]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.99      0.95      7094\n",
            "           1       0.61      0.17      0.26       822\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.76      0.58      0.61      7916\n",
            "weighted avg       0.88      0.90      0.88      7916\n",
            "\n",
            "-----------GROUP4 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6973  121]\n",
            " [ 663  159]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.95      7094\n",
            "           1       0.57      0.19      0.29       822\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.74      0.59      0.62      7916\n",
            "weighted avg       0.88      0.90      0.88      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HA0eFZOr0i8u"
      },
      "source": [
        "#Group 1, 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gx78KoWj0ks0",
        "outputId": "8b333e56-8cd4-450f-89b0-54bb90a99ad7"
      },
      "source": [
        "gr12data = data.drop(columns=['day','month','duration','campaign','pdays','previous','poutcome'])\n",
        "X = gr12data.drop(['y'], axis=1)\n",
        "y = gr12data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,2 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(9,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,2 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,2 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,2 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 9) (39579,)\n",
            "----------GROUP 1,2 Using SVM------------\n",
            "Confusion matrix\n",
            "[[7039    0]\n",
            " [ 877    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7039\n",
            "           1       0.00      0.00      0.00       877\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.44      0.50      0.47      7916\n",
            "weighted avg       0.79      0.89      0.84      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 4s 3ms/step - loss: 0.3356 - accuracy: 0.8910\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3234 - accuracy: 0.8915\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3195 - accuracy: 0.8919\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3164 - accuracy: 0.8915\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3151 - accuracy: 0.8921\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3134 - accuracy: 0.8919\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3121 - accuracy: 0.8928\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.3106 - accuracy: 0.8922\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3094 - accuracy: 0.8924\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3083 - accuracy: 0.8926\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3071 - accuracy: 0.8924\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3060 - accuracy: 0.8928\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3053 - accuracy: 0.8932\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3042 - accuracy: 0.8940\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3026 - accuracy: 0.8934\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3017 - accuracy: 0.8939\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.3011 - accuracy: 0.8937\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2999 - accuracy: 0.8934\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2993 - accuracy: 0.8944\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2978 - accuracy: 0.8952\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2968 - accuracy: 0.8957\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2963 - accuracy: 0.8949\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2945 - accuracy: 0.8957\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2934 - accuracy: 0.8963\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2926 - accuracy: 0.8960\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2918 - accuracy: 0.8971\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2909 - accuracy: 0.8969\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2900 - accuracy: 0.8971\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2889 - accuracy: 0.8965\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2882 - accuracy: 0.8975\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2867 - accuracy: 0.8974\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2862 - accuracy: 0.8975\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2852 - accuracy: 0.8990\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2844 - accuracy: 0.8980\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2830 - accuracy: 0.8993\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2822 - accuracy: 0.8990\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2816 - accuracy: 0.8993\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2799 - accuracy: 0.8994\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2788 - accuracy: 0.9003\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2784 - accuracy: 0.8996\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2778 - accuracy: 0.9003\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2761 - accuracy: 0.9010\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2754 - accuracy: 0.9014\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2749 - accuracy: 0.9012\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2738 - accuracy: 0.9017\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2723 - accuracy: 0.9017\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2713 - accuracy: 0.9017\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2707 - accuracy: 0.9028\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2686 - accuracy: 0.9024\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2688 - accuracy: 0.9030\n",
            "-----------GROUP 1,2 Using NN------------\n",
            "Confusion matrix\n",
            "[[6905  134]\n",
            " [ 772  105]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94      7039\n",
            "           1       0.44      0.12      0.19       877\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.67      0.55      0.56      7916\n",
            "weighted avg       0.85      0.89      0.86      7916\n",
            "\n",
            "-----------GROUP 1,2 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[7039    0]\n",
            " [ 877    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7039\n",
            "           1       0.00      0.00      0.00       877\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.44      0.50      0.47      7916\n",
            "weighted avg       0.79      0.89      0.84      7916\n",
            "\n",
            "-----------GROUP 1,2 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[7039    0]\n",
            " [ 877    0]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      1.00      0.94      7039\n",
            "           1       0.00      0.00      0.00       877\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.44      0.50      0.47      7916\n",
            "weighted avg       0.79      0.89      0.84      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wl4YVgHk1BkL"
      },
      "source": [
        "##Group 1, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HOw67iPP1Dhn",
        "outputId": "6973abd0-8b52-4b07-b56c-8a4b9c255508"
      },
      "source": [
        "gr13data = data.drop(columns=['housing','loan','balance','month_int'])\n",
        "X = gr13data.drop(['y'], axis=1)\n",
        "y = gr13data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,3 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(12,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,3 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,3 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,3 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 12) (39579,)\n",
            "----------GROUP 1,3 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6894  134]\n",
            " [ 635  253]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7028\n",
            "           1       0.65      0.28      0.40       888\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.78      0.63      0.67      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2560 - accuracy: 0.8978\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2328 - accuracy: 0.9066\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2262 - accuracy: 0.9088\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2223 - accuracy: 0.9102\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2201 - accuracy: 0.9113\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2177 - accuracy: 0.9125\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2155 - accuracy: 0.9131\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2140 - accuracy: 0.9138\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2118 - accuracy: 0.9144\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2108 - accuracy: 0.9144\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2085 - accuracy: 0.9153\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2067 - accuracy: 0.9155\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2049 - accuracy: 0.9161\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2029 - accuracy: 0.9183\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2013 - accuracy: 0.9194\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1991 - accuracy: 0.9198\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1969 - accuracy: 0.9195\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1954 - accuracy: 0.9216\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1926 - accuracy: 0.9220\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1908 - accuracy: 0.9220\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9238\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1868 - accuracy: 0.9235\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1848 - accuracy: 0.9248\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1834 - accuracy: 0.9251\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1801 - accuracy: 0.9265\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1783 - accuracy: 0.9266\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1754 - accuracy: 0.9285\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1745 - accuracy: 0.9280\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.9296\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1694 - accuracy: 0.9321\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1683 - accuracy: 0.9308\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1657 - accuracy: 0.9328\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1629 - accuracy: 0.9333\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1613 - accuracy: 0.9345\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1590 - accuracy: 0.9337\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1551 - accuracy: 0.9362\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1532 - accuracy: 0.9380\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1514 - accuracy: 0.9384\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1494 - accuracy: 0.9389\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1460 - accuracy: 0.9406\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1458 - accuracy: 0.9401\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1436 - accuracy: 0.9400\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1404 - accuracy: 0.9423\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1383 - accuracy: 0.9435\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1363 - accuracy: 0.9434\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1350 - accuracy: 0.9441\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1321 - accuracy: 0.9457\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1289 - accuracy: 0.9466\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1286 - accuracy: 0.9482\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1266 - accuracy: 0.9477\n",
            "-----------GROUP 1,3 Using NN------------\n",
            "Confusion matrix\n",
            "[[6761  267]\n",
            " [ 528  360]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      7028\n",
            "           1       0.57      0.41      0.48       888\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.75      0.68      0.71      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n",
            "-----------GROUP 1,3 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6917  111]\n",
            " [ 723  165]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      7028\n",
            "           1       0.60      0.19      0.28       888\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.75      0.59      0.61      7916\n",
            "weighted avg       0.87      0.89      0.87      7916\n",
            "\n",
            "-----------GROUP 1,3 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6837  191]\n",
            " [ 579  309]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95      7028\n",
            "           1       0.62      0.35      0.45       888\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.77      0.66      0.70      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffijawRv1S7T"
      },
      "source": [
        "##Group 1, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_J9lUsKl1WI8",
        "outputId": "227be9a8-e4c9-4166-cd19-c8d0dbc1a051"
      },
      "source": [
        "gr14data = data.drop(columns=['housing','loan','month_int','month','campaign','pdays','previous','poutcome'])\n",
        "X = gr14data.drop(['y'], axis=1)\n",
        "y = gr14data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(8,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 8) (39579,)\n",
            "----------GROUP 1,4 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6940   95]\n",
            " [ 774  107]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94      7035\n",
            "           1       0.53      0.12      0.20       881\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.71      0.55      0.57      7916\n",
            "weighted avg       0.86      0.89      0.86      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2750 - accuracy: 0.8971\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2622 - accuracy: 0.8985\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2588 - accuracy: 0.8986\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2570 - accuracy: 0.8997\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2553 - accuracy: 0.8999\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2541 - accuracy: 0.9000\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2527 - accuracy: 0.9006\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2512 - accuracy: 0.9006\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2505 - accuracy: 0.8997\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2495 - accuracy: 0.9003\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2488 - accuracy: 0.9002\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2477 - accuracy: 0.9022\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2461 - accuracy: 0.9030\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2454 - accuracy: 0.9020\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2441 - accuracy: 0.9029\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2437 - accuracy: 0.9028\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2421 - accuracy: 0.9035\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2415 - accuracy: 0.9024\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2404 - accuracy: 0.9042\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2390 - accuracy: 0.9042\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2384 - accuracy: 0.9046\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2371 - accuracy: 0.9042\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2362 - accuracy: 0.9049\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2342 - accuracy: 0.9065\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2337 - accuracy: 0.9058\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2323 - accuracy: 0.9056\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2315 - accuracy: 0.9061\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2297 - accuracy: 0.9066\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2293 - accuracy: 0.9072\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2278 - accuracy: 0.9071\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2272 - accuracy: 0.9070\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2258 - accuracy: 0.9085\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2239 - accuracy: 0.9091\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2231 - accuracy: 0.9094\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2215 - accuracy: 0.9105\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2200 - accuracy: 0.9108\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2199 - accuracy: 0.9106\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2179 - accuracy: 0.9112\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2164 - accuracy: 0.9108\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2149 - accuracy: 0.9137\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2137 - accuracy: 0.9138\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2120 - accuracy: 0.9131\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2114 - accuracy: 0.9135\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2095 - accuracy: 0.9150\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2082 - accuracy: 0.9152\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2068 - accuracy: 0.9159\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2050 - accuracy: 0.9155\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2044 - accuracy: 0.9165\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2020 - accuracy: 0.9164\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2003 - accuracy: 0.9178\n",
            "-----------GROUP 1,4 Using NN------------\n",
            "Confusion matrix\n",
            "[[6794  241]\n",
            " [ 661  220]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94      7035\n",
            "           1       0.48      0.25      0.33       881\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.69      0.61      0.63      7916\n",
            "weighted avg       0.86      0.89      0.87      7916\n",
            "\n",
            "-----------GROUP 1,4 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6922  113]\n",
            " [ 749  132]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.98      0.94      7035\n",
            "           1       0.54      0.15      0.23       881\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.72      0.57      0.59      7916\n",
            "weighted avg       0.86      0.89      0.86      7916\n",
            "\n",
            "-----------GROUP 1,4 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6882  153]\n",
            " [ 701  180]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      7035\n",
            "           1       0.54      0.20      0.30       881\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.72      0.59      0.62      7916\n",
            "weighted avg       0.87      0.89      0.87      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4wn2gK_1vjB"
      },
      "source": [
        "##Group 2, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mHxqokox1x6R",
        "outputId": "15e79216-ea26-4582-98b3-841de364b924"
      },
      "source": [
        "gr23data = data.drop(columns=['age','job','marital','education','default'])\n",
        "X = gr23data.drop(['y'], axis=1)\n",
        "y = gr23data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 2,3 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(11,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 2,3 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 2,3 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 2,3 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 11) (39579,)\n",
            "----------GROUP 2,3 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6897  130]\n",
            " [ 628  261]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7027\n",
            "           1       0.67      0.29      0.41       889\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.79      0.64      0.68      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2390 - accuracy: 0.9027\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2185 - accuracy: 0.9072\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2108 - accuracy: 0.9095\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2051 - accuracy: 0.9120\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2019 - accuracy: 0.9127\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1991 - accuracy: 0.9143\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1957 - accuracy: 0.9155\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1932 - accuracy: 0.9165\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1920 - accuracy: 0.9173\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1901 - accuracy: 0.9181\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1883 - accuracy: 0.9186\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1871 - accuracy: 0.9198\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1846 - accuracy: 0.9209\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1837 - accuracy: 0.9200\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1822 - accuracy: 0.9216\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1806 - accuracy: 0.9218\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1796 - accuracy: 0.9220\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1784 - accuracy: 0.9244\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1773 - accuracy: 0.9232\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1754 - accuracy: 0.9241\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1739 - accuracy: 0.9246\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1733 - accuracy: 0.9254\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1714 - accuracy: 0.9257\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1704 - accuracy: 0.9272\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1684 - accuracy: 0.9284\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1672 - accuracy: 0.9284\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1656 - accuracy: 0.9288\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1649 - accuracy: 0.9286\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1637 - accuracy: 0.9300\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1620 - accuracy: 0.9301\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1611 - accuracy: 0.9321\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1594 - accuracy: 0.9312\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1586 - accuracy: 0.9320\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1573 - accuracy: 0.9314\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1561 - accuracy: 0.9328\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1551 - accuracy: 0.9329\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1534 - accuracy: 0.9340\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1517 - accuracy: 0.9353\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1512 - accuracy: 0.9347\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1506 - accuracy: 0.9345\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1480 - accuracy: 0.9369\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1486 - accuracy: 0.9370\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1465 - accuracy: 0.9379\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1462 - accuracy: 0.9377\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1439 - accuracy: 0.9387\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1433 - accuracy: 0.9393\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1414 - accuracy: 0.9399\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1400 - accuracy: 0.9401\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1398 - accuracy: 0.9408\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1378 - accuracy: 0.9419\n",
            "-----------GROUP 2,3 Using NN------------\n",
            "Confusion matrix\n",
            "[[6729  298]\n",
            " [ 461  428]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.96      0.95      7027\n",
            "           1       0.59      0.48      0.53       889\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.76      0.72      0.74      7916\n",
            "weighted avg       0.90      0.90      0.90      7916\n",
            "\n",
            "-----------GROUP 2,3 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6907  120]\n",
            " [ 702  187]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      7027\n",
            "           1       0.61      0.21      0.31       889\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.76      0.60      0.63      7916\n",
            "weighted avg       0.87      0.90      0.87      7916\n",
            "\n",
            "-----------GROUP 2,3 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6817  210]\n",
            " [ 574  315]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.97      0.95      7027\n",
            "           1       0.60      0.35      0.45       889\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.76      0.66      0.70      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX1KOzi92EPR"
      },
      "source": [
        "##Group 2, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kWlRouWc2F70",
        "outputId": "cbc04b6c-f572-4b9c-8f38-67b994bf2e0d"
      },
      "source": [
        "gr24data = data.drop(columns=['job','marital','education','default','month','campaign','pdays','previous','poutcome'])\n",
        "X = gr24data.drop(['y'], axis=1)\n",
        "y = gr24data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 2,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(7,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 2,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 2,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 2,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 7) (39579,)\n",
            "----------GROUP 2,4 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6944   94]\n",
            " [ 736  142]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.99      0.94      7038\n",
            "           1       0.60      0.16      0.25       878\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.75      0.57      0.60      7916\n",
            "weighted avg       0.87      0.90      0.87      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2625 - accuracy: 0.8948\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2408 - accuracy: 0.9009\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2347 - accuracy: 0.9008\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2294 - accuracy: 0.9038\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2252 - accuracy: 0.9040\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2211 - accuracy: 0.9057\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2190 - accuracy: 0.9066\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2167 - accuracy: 0.9063\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2153 - accuracy: 0.9081\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2138 - accuracy: 0.9080\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2116 - accuracy: 0.9093\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2101 - accuracy: 0.9095\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2091 - accuracy: 0.9098\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2075 - accuracy: 0.9096\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2065 - accuracy: 0.9110\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2059 - accuracy: 0.9110\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2047 - accuracy: 0.9118\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2042 - accuracy: 0.9128\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2024 - accuracy: 0.9137\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2009 - accuracy: 0.9137\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2013 - accuracy: 0.9126\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1997 - accuracy: 0.9139\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1985 - accuracy: 0.9151\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1972 - accuracy: 0.9160\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1963 - accuracy: 0.9163\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1959 - accuracy: 0.9150\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1935 - accuracy: 0.9168\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1936 - accuracy: 0.9164\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1927 - accuracy: 0.9161\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1915 - accuracy: 0.9182\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1905 - accuracy: 0.9180\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1898 - accuracy: 0.9175\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1890 - accuracy: 0.9180\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1880 - accuracy: 0.9193\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1869 - accuracy: 0.9196\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1854 - accuracy: 0.9198\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1853 - accuracy: 0.9203\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1837 - accuracy: 0.9217\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1828 - accuracy: 0.9215\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1832 - accuracy: 0.9210\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1809 - accuracy: 0.9222\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1798 - accuracy: 0.9226\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1782 - accuracy: 0.9229\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1778 - accuracy: 0.9239\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1769 - accuracy: 0.9236\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1766 - accuracy: 0.9246\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1746 - accuracy: 0.9251\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1744 - accuracy: 0.9263\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1724 - accuracy: 0.9259\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1715 - accuracy: 0.9263\n",
            "-----------GROUP 2,4 Using NN------------\n",
            "Confusion matrix\n",
            "[[6768  270]\n",
            " [ 518  360]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.94      7038\n",
            "           1       0.57      0.41      0.48       878\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.75      0.69      0.71      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n",
            "-----------GROUP 2,4 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6909  129]\n",
            " [ 706  172]]\n",
            "Accuracy\n",
            "89.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      7038\n",
            "           1       0.57      0.20      0.29       878\n",
            "\n",
            "    accuracy                           0.89      7916\n",
            "   macro avg       0.74      0.59      0.62      7916\n",
            "weighted avg       0.87      0.89      0.87      7916\n",
            "\n",
            "-----------GROUP 2,4 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6894  144]\n",
            " [ 686  192]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94      7038\n",
            "           1       0.57      0.22      0.32       878\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.74      0.60      0.63      7916\n",
            "weighted avg       0.87      0.90      0.87      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5hcDwZ3r2fUg"
      },
      "source": [
        "##Group 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pWzvifoS2g58",
        "outputId": "9bbb1f0a-e8ce-474d-e980-7576eb2d7fc9"
      },
      "source": [
        "gr34data = data.drop(columns=['job','marital','education','default','housing','loan','month_int'])\n",
        "X = gr34data.drop(['y'], axis=1)\n",
        "y = gr34data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 3,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(9,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 3,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 3,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 3,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 9) (39579,)\n",
            "----------GROUP 3,4 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6940  132]\n",
            " [ 561  283]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.98      0.95      7072\n",
            "           1       0.68      0.34      0.45       844\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.80      0.66      0.70      7916\n",
            "weighted avg       0.90      0.91      0.90      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2556 - accuracy: 0.8996\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2372 - accuracy: 0.9041\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2323 - accuracy: 0.9050\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2295 - accuracy: 0.9065\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2262 - accuracy: 0.9087\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2243 - accuracy: 0.9091\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2213 - accuracy: 0.9094\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2200 - accuracy: 0.9099\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2189 - accuracy: 0.9109\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2160 - accuracy: 0.9117\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2145 - accuracy: 0.9128\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2133 - accuracy: 0.9127\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.2121 - accuracy: 0.9141\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2104 - accuracy: 0.9143\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2094 - accuracy: 0.9141\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2076 - accuracy: 0.9149\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2056 - accuracy: 0.9162\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2042 - accuracy: 0.9172\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2026 - accuracy: 0.9169\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2017 - accuracy: 0.9181\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2002 - accuracy: 0.9181\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1978 - accuracy: 0.9189\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1969 - accuracy: 0.9202\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1950 - accuracy: 0.9203\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1924 - accuracy: 0.9208\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1919 - accuracy: 0.9208\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1899 - accuracy: 0.9221\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1888 - accuracy: 0.9227\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1869 - accuracy: 0.9215\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1847 - accuracy: 0.9234\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1831 - accuracy: 0.9251\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1817 - accuracy: 0.9251\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1799 - accuracy: 0.9263\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1789 - accuracy: 0.9260\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1758 - accuracy: 0.9276\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1746 - accuracy: 0.9274\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1726 - accuracy: 0.9278\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1724 - accuracy: 0.9280\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1696 - accuracy: 0.9294\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1676 - accuracy: 0.9299\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1659 - accuracy: 0.9309\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1661 - accuracy: 0.9319\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1645 - accuracy: 0.9331\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1617 - accuracy: 0.9338\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1595 - accuracy: 0.9341\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1591 - accuracy: 0.9346\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1567 - accuracy: 0.9349\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1559 - accuracy: 0.9356\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1562 - accuracy: 0.9363\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1542 - accuracy: 0.9371\n",
            "-----------GROUP 3,4 Using NN------------\n",
            "Confusion matrix\n",
            "[[6814  258]\n",
            " [ 487  357]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.96      0.95      7072\n",
            "           1       0.58      0.42      0.49       844\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.76      0.69      0.72      7916\n",
            "weighted avg       0.90      0.91      0.90      7916\n",
            "\n",
            "-----------GROUP 3,4 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6958  114]\n",
            " [ 684  160]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.95      7072\n",
            "           1       0.58      0.19      0.29       844\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.75      0.59      0.62      7916\n",
            "weighted avg       0.88      0.90      0.88      7916\n",
            "\n",
            "-----------GROUP 3,4 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6892  180]\n",
            " [ 543  301]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      7072\n",
            "           1       0.63      0.36      0.45       844\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.78      0.67      0.70      7916\n",
            "weighted avg       0.89      0.91      0.90      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObTYRFB72-1v"
      },
      "source": [
        "##Group 1, 2, 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DVv1bam83Bqe",
        "outputId": "82790648-c979-4b06-8251-49cdcc78cbca"
      },
      "source": [
        "X = data.drop(['y'], axis=1)\n",
        "y = data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,2,3 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(16,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,2,3 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,2,3 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,2,3 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(39579, 16) (39579,)\n",
            "----------GROUP 1,2,3 Using SVM------------\n",
            "Confusion matrix\n",
            "[[6956  117]\n",
            " [ 598  245]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7073\n",
            "           1       0.68      0.29      0.41       843\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.80      0.64      0.68      7916\n",
            "weighted avg       0.89      0.91      0.89      7916\n",
            "\n",
            "Epoch 1/50\n",
            "990/990 [==============================] - 3s 2ms/step - loss: 0.2458 - accuracy: 0.8971\n",
            "Epoch 2/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2224 - accuracy: 0.9053\n",
            "Epoch 3/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2157 - accuracy: 0.9069\n",
            "Epoch 4/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2095 - accuracy: 0.9094\n",
            "Epoch 5/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.2040 - accuracy: 0.9110\n",
            "Epoch 6/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1990 - accuracy: 0.9136\n",
            "Epoch 7/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1950 - accuracy: 0.9157\n",
            "Epoch 8/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1918 - accuracy: 0.9155\n",
            "Epoch 9/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1884 - accuracy: 0.9163\n",
            "Epoch 10/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1852 - accuracy: 0.9191\n",
            "Epoch 11/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1823 - accuracy: 0.9201\n",
            "Epoch 12/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1787 - accuracy: 0.9216\n",
            "Epoch 13/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1756 - accuracy: 0.9240\n",
            "Epoch 14/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1729 - accuracy: 0.9241\n",
            "Epoch 15/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1700 - accuracy: 0.9262\n",
            "Epoch 16/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1684 - accuracy: 0.9260\n",
            "Epoch 17/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1643 - accuracy: 0.9281\n",
            "Epoch 18/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.1617 - accuracy: 0.9298\n",
            "Epoch 19/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1588 - accuracy: 0.9314\n",
            "Epoch 20/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1556 - accuracy: 0.9335\n",
            "Epoch 21/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1539 - accuracy: 0.9340\n",
            "Epoch 22/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1500 - accuracy: 0.9356\n",
            "Epoch 23/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1462 - accuracy: 0.9361\n",
            "Epoch 24/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.1447 - accuracy: 0.9378\n",
            "Epoch 25/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.1413 - accuracy: 0.9393\n",
            "Epoch 26/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1384 - accuracy: 0.9414\n",
            "Epoch 27/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1360 - accuracy: 0.9432\n",
            "Epoch 28/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1323 - accuracy: 0.9455\n",
            "Epoch 29/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1288 - accuracy: 0.9460\n",
            "Epoch 30/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1260 - accuracy: 0.9458\n",
            "Epoch 31/50\n",
            "990/990 [==============================] - 2s 3ms/step - loss: 0.1252 - accuracy: 0.9477\n",
            "Epoch 32/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1205 - accuracy: 0.9496\n",
            "Epoch 33/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1189 - accuracy: 0.9507\n",
            "Epoch 34/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1151 - accuracy: 0.9520\n",
            "Epoch 35/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1134 - accuracy: 0.9515\n",
            "Epoch 36/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1097 - accuracy: 0.9546\n",
            "Epoch 37/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.1079 - accuracy: 0.9557\n",
            "Epoch 38/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.1045 - accuracy: 0.9570\n",
            "Epoch 39/50\n",
            "990/990 [==============================] - 3s 3ms/step - loss: 0.1037 - accuracy: 0.9573\n",
            "Epoch 40/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.1002 - accuracy: 0.9584\n",
            "Epoch 41/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0968 - accuracy: 0.9607\n",
            "Epoch 42/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0948 - accuracy: 0.9608\n",
            "Epoch 43/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0932 - accuracy: 0.9612\n",
            "Epoch 44/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0903 - accuracy: 0.9632\n",
            "Epoch 45/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0881 - accuracy: 0.9649\n",
            "Epoch 46/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0856 - accuracy: 0.9653\n",
            "Epoch 47/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0835 - accuracy: 0.9644\n",
            "Epoch 48/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0832 - accuracy: 0.9656\n",
            "Epoch 49/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0783 - accuracy: 0.9682\n",
            "Epoch 50/50\n",
            "990/990 [==============================] - 2s 2ms/step - loss: 0.0792 - accuracy: 0.9678\n",
            "-----------GROUP 1,2,3 Using NN------------\n",
            "Confusion matrix\n",
            "[[6719  354]\n",
            " [ 471  372]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94      7073\n",
            "           1       0.51      0.44      0.47       843\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.72      0.70      0.71      7916\n",
            "weighted avg       0.89      0.90      0.89      7916\n",
            "\n",
            "-----------GROUP 1,2,3 Using Logistic Regression------------\n",
            "Confusion matrix\n",
            "[[6949  124]\n",
            " [ 643  200]]\n",
            "Accuracy\n",
            "90.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95      7073\n",
            "           1       0.62      0.24      0.34       843\n",
            "\n",
            "    accuracy                           0.90      7916\n",
            "   macro avg       0.77      0.61      0.65      7916\n",
            "weighted avg       0.88      0.90      0.88      7916\n",
            "\n",
            "-----------GROUP 1,2,3 Using Decision Tree------------\n",
            "Confusion matrix\n",
            "[[6863  210]\n",
            " [ 535  308]]\n",
            "Accuracy\n",
            "91.0\n",
            "Classification Report\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.97      0.95      7073\n",
            "           1       0.59      0.37      0.45       843\n",
            "\n",
            "    accuracy                           0.91      7916\n",
            "   macro avg       0.76      0.67      0.70      7916\n",
            "weighted avg       0.89      0.91      0.90      7916\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmsB3O0e3M5j"
      },
      "source": [
        "##Group 1, 2, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6yDLCqF3Phx"
      },
      "source": [
        "gr124data = data.drop(columns=['month','campaign','pdays','previous','poutcome'])\n",
        "X = gr124data.drop(['y'], axis=1)\n",
        "y = gr124data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,2,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(11,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,2,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,2,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,2,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnYG1Ga23jOu"
      },
      "source": [
        "##Group 1, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcHNG05d3lg_"
      },
      "source": [
        "gr134data = data.drop(columns=['housing','loan','month_int'])\n",
        "X = gr134data.drop(['y'], axis=1)\n",
        "y = gr134data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,3,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(13,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,3,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,3,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,3,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeKXE2C330kj"
      },
      "source": [
        "##Group 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOshlaa532hG"
      },
      "source": [
        "gr234data = data.drop(columns=['job','marital','education','default'])\n",
        "X = gr234data.drop(['y'], axis=1)\n",
        "y = gr234data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 2,3,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(12,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 2,3,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 2,3,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 2,3,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv_LH1Tj4Dzb"
      },
      "source": [
        "##Group 1, 2, 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKlMWI4L4FyG"
      },
      "source": [
        "X = data.drop(['y'], axis=1)\n",
        "y = data['y']\n",
        "print(X.shape, y.shape)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "#SVM\n",
        "svm = SVC(kernel = 'rbf', probability=True)\n",
        "svm.fit(X_train, y_train)\n",
        "svmpred = svm.predict(X_test)\n",
        "\n",
        "probs = svm.predict_proba(X_test)\n",
        "preds = probs[:,1]\n",
        "print(\"----------GROUP 1,2,3,4 Using SVM------------\")\n",
        "score(y_test, svmpred)\n",
        "\n",
        "#Neural Networks\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "model=keras.Sequential([\n",
        "    keras.layers.Dense(50, input_shape=(16,), activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(100, activation=\"relu\"),\n",
        "    keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "])\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, epochs=50)\n",
        "nn_pred = model.predict(X_test)\n",
        "nn_pred[nn_pred<=0.5]=0\n",
        "nn_pred[nn_pred>0.5]=1\n",
        "print(\"-----------GROUP 1,2,3,4 Using NN------------\")\n",
        "score(y_test,nn_pred)\n",
        "\n",
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)\n",
        "#Predicting the test set results and caculating the accuracy\n",
        "logreg_pred = logreg.predict(X_test)\n",
        "print(\"-----------GROUP 1,2,3,4 Using Logistic Regression------------\")\n",
        "score(y_test,logreg_pred)\n",
        "\n",
        "#Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decisionTreeClassifier():\n",
        "\n",
        "    model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n",
        "    model = model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    print(\"-----------GROUP 1,2,3,4 Using Decision Tree------------\")\n",
        "    score(y_test,predictions)\n",
        "\n",
        "decisionTreeClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}